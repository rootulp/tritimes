# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

TriTimes is a Next.js web application that lets athletes view their historical IronMan and IronMan 70.3 triathlon results. For each result, it shows statistical distributions for each discipline (swim, bike, run) and total time, comparing performance against the athlete's age group and overall field.

Data is collected from https://www.ironman.com/races/im703-new-york/results. Inspired by https://www.hyresult.com/.

## Architecture

- **`app/`** — Next.js 16 app with React 19, TypeScript, Tailwind CSS v4, Recharts
- **`scripts/`** — Node.js data pipeline scripts (zero dependencies, requires Node 18+)
- **`data/`** — Race result CSVs and `races.json` manifest

## Data Strategy

- **CSVs** (`data/*.csv`) are committed to git (~400 KB per race)
- **Raw JSON** (`data/raw/`) is gitignored (~10 MB per race)
- **Manifest** (`data/races.json`) lists all races; auto-generated by scraper, read by app at build time
- The app reads races from `data/races.json` — adding a new race only requires running the scraper, no code changes

## Key File Paths

- `app/src/lib/data.ts` — Server-side data access (reads CSVs, computes histograms)
- `app/src/lib/types.ts` — TypeScript interfaces
- `app/src/app/page.tsx` — Landing page with global search
- `app/src/app/race/[slug]/result/[id]/page.tsx` — Individual athlete result page
- `scripts/scrape.js` — Single-race scraper (also exports reusable functions)
- `scripts/discover.js` — Discovers event IDs from ironman.com or competitor.com URLs
- `scripts/scrape-all.js` — Batch scraper using race-registry.json
- `scripts/race-registry.json` — Registry of known races with group URLs
- `data/races.json` — Race manifest consumed by the app

## Commands

```bash
# Development
cd app && npm run dev

# Build
cd app && npm run build

# Scrape a single race
node scripts/scrape.js <slug> [event-id] [--no-raw]

# Discover event IDs
node scripts/discover.js <url>

# Batch scrape
node scripts/scrape-all.js [--slug=<slug>] [--year=2025] [--dry-run] [--save-raw]
```
